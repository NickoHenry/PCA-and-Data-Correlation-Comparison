{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN - Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtea5ekUcEdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d07508e-0cdd-46d4-e1e6-dfa1b501ee12"
      },
      "source": [
        "!pip install --upgrade tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=6eee0030743efbf5a0b6b2c66202518c9d5140a7f31650adb4fa943e33106425\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, keras-applications, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPDVvtC9cXKP"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-XsLQ28c69D"
      },
      "source": [
        "dataset = pd.read_csv ('b_depressed.csv')\n",
        "dataset = dataset.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6M4MwSOrSNI"
      },
      "source": [
        "\n",
        "\n",
        "> Non-PCA + All Inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol0qZFNuc8RB"
      },
      "source": [
        "x_features = dataset[['sex', 'Age', 'Married', 'Number_children', 'education_level', 'total_members', 'gained_asset', 'durable_asset', 'save_asset', 'living_expenses', 'other_expenses', 'incoming_salary', 'incoming_own_farm', 'incoming_business', 'incoming_no_business', 'incoming_agricultural', 'farm_expenses', 'labor_primary', 'lasting_investment', 'no_lasting_investmen']].values\n",
        "y_target = dataset[['depressed']].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZoO4g95c9U9"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split (x_features, y_target, test_size = 0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqhuBpImc-VI"
      },
      "source": [
        "scaler = StandardScaler().fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysjDhARQc_mR"
      },
      "source": [
        "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
        "y_train, y_test = y_train.astype('float32'), y_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyOvdyG6dA5s"
      },
      "source": [
        "layers = {\n",
        "    'input' : 20,\n",
        "    'hidden' : 1,\n",
        "    'output' : 1\n",
        "}\n",
        "\n",
        "input_hidden = {\n",
        "    'weight': tf.Variable(tf.random_normal([layers['input'], layers['hidden']], seed=0)),\n",
        "    'bias': tf.Variable(tf.random_normal([layers['hidden']], seed=0))\n",
        "}\n",
        "\n",
        "hidden_output = {\n",
        "    'weight': tf.Variable(tf.random_normal([layers['hidden'], layers['output']], seed=0)),\n",
        "    'bias': tf.Variable(tf.random_normal([layers['output']], seed=0))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChrDjC5EdDPY"
      },
      "source": [
        "def feed_forward(input):\n",
        "  x1 = tf.matmul(input, input_hidden['weight']) + input_hidden['bias']\n",
        "  y1 = tf.nn.sigmoid(x1)\n",
        "\n",
        "  x2 = tf.matmul(y1, hidden_output['weight']) + hidden_output['bias']\n",
        "  y2 = tf.nn.sigmoid(x2)\n",
        "\n",
        "  return y2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-xG8nyEdEoM"
      },
      "source": [
        "input_placeholder = tf.placeholder(tf.float32, [None, layers['input']])\n",
        "output_placeholder = tf.placeholder(tf.float32, [None, layers['output']])\n",
        "\n",
        "output = feed_forward(input_placeholder)\n",
        "error = tf.reduce_mean(0.5 * (output_placeholder - output) ** 2)\n",
        "\n",
        "learning_rate = 0.2\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkA51mCLdJZM",
        "outputId": "1d37ae59-4a3e-4368-b8f3-7ef4b020c466"
      },
      "source": [
        "epoch = 200\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for i in range(epoch):\n",
        "    train_dict = {\n",
        "        input_placeholder: x_train,\n",
        "        output_placeholder: y_train\n",
        "    }\n",
        "    \n",
        "    sess.run(train, feed_dict=train_dict)\n",
        "    curr_error = sess.run(error, feed_dict=train_dict)\n",
        "    if i % 10 == 0:\n",
        "      accuracy = tf.equal(tf.argmax(output_placeholder, axis = 1), tf.argmax(output, axis=1))\n",
        "      accuracy_final = tf.reduce_mean(tf.cast(accuracy, tf.float32))\n",
        "\n",
        "      test_dict = {\n",
        "          input_placeholder: x_test,\n",
        "          output_placeholder: y_test\n",
        "      }\n",
        "\n",
        "      print(\"Error: {}\".format(sess.run(error, feed_dict=test_dict)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.08789081126451492\n",
            "Error: 0.08382114768028259\n",
            "Error: 0.08069551736116409\n",
            "Error: 0.07825588434934616\n",
            "Error: 0.07632222771644592\n",
            "Error: 0.0747675895690918\n",
            "Error: 0.07350121438503265\n",
            "Error: 0.07245724648237228\n",
            "Error: 0.07158716022968292\n",
            "Error: 0.07085475325584412\n",
            "Error: 0.0702325776219368\n",
            "Error: 0.06969963014125824\n",
            "Error: 0.06923957914113998\n",
            "Error: 0.06883963197469711\n",
            "Error: 0.06848962604999542\n",
            "Error: 0.06818144768476486\n",
            "Error: 0.06790855526924133\n",
            "Error: 0.06766558438539505\n",
            "Error: 0.06744817644357681\n",
            "Error: 0.06725272536277771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-vhPr9qoniN"
      },
      "source": [
        "Non-PCA + All inputs\n",
        "\n",
        "---\n",
        "\n",
        "**1 hidden neuron = 0.0672**\n",
        "\n",
        "5 hidden neuron = 0.0678\n",
        "\n",
        "10 hidden neuron = 0.0739\n",
        "\n",
        "15 hidden neuron = 0.0704\n",
        "\n",
        "20 hidden neuron = 0.0697\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMQfvxYwrNNi"
      },
      "source": [
        "\n",
        "\n",
        "> Non-PCA + Correlated Inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KufdvnZep7pz",
        "outputId": "81c0f935-b9ef-4b66-9c47-e97d36d2e8cf"
      },
      "source": [
        "dataset.corr()['depressed'].sort_values()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "education_level         -0.097361\n",
              "Married                 -0.063588\n",
              "incoming_business       -0.028586\n",
              "incoming_no_business    -0.026104\n",
              "living_expenses         -0.024149\n",
              "incoming_agricultural   -0.019415\n",
              "labor_primary           -0.010302\n",
              "Survey_id               -0.010181\n",
              "sex                     -0.005700\n",
              "gained_asset            -0.005111\n",
              "farm_expenses           -0.005059\n",
              "incoming_salary         -0.001813\n",
              "Number_children          0.003406\n",
              "lasting_investment       0.004459\n",
              "incoming_own_farm        0.010019\n",
              "other_expenses           0.011107\n",
              "save_asset               0.011379\n",
              "Ville_id                 0.027938\n",
              "total_members            0.033125\n",
              "durable_asset            0.038323\n",
              "no_lasting_investmen     0.051973\n",
              "Age                      0.100126\n",
              "depressed                1.000000\n",
              "Name: depressed, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQKdqvnq5Ju"
      },
      "source": [
        "x_corr = dataset[['Age', 'Married', 'education_level', 'no_lasting_investmen']].values\n",
        "y_corr = dataset[['depressed']].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLsSPPu6rG7I"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split (x_corr, y_corr, test_size = 0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVscN8FNrYzu"
      },
      "source": [
        "scaler = StandardScaler().fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJV4r9vSraZH"
      },
      "source": [
        "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
        "y_train, y_test = y_train.astype('float32'), y_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FLBntKarcLn"
      },
      "source": [
        "layers = {\n",
        "    'input' : 4,\n",
        "    'hidden' : 1,\n",
        "    'output' : 1\n",
        "}\n",
        "\n",
        "input_hidden = {\n",
        "    'weight': tf.Variable(tf.random_normal([layers['input'], layers['hidden']], seed=0)),\n",
        "    'bias': tf.Variable(tf.random_normal([layers['hidden']], seed=0))\n",
        "}\n",
        "\n",
        "hidden_output = {\n",
        "    'weight': tf.Variable(tf.random_normal([layers['hidden'], layers['output']], seed=0)),\n",
        "    'bias': tf.Variable(tf.random_normal([layers['output']], seed=0))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi9QxWIQsn2U"
      },
      "source": [
        "input_placeholder = tf.placeholder(tf.float32, [None, layers['input']])\n",
        "output_placeholder = tf.placeholder(tf.float32, [None, layers['output']])\n",
        "\n",
        "output = feed_forward(input_placeholder)\n",
        "error = tf.reduce_mean(0.5 * (output_placeholder - output) ** 2)\n",
        "\n",
        "learning_rate = 0.2\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A67JFoiQssQ9",
        "outputId": "bb741039-ee2f-49cd-9463-756c2b029620"
      },
      "source": [
        "epoch = 200\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for i in range(epoch):\n",
        "    train_dict = {\n",
        "        input_placeholder: x_train,\n",
        "        output_placeholder: y_train\n",
        "    }\n",
        "    \n",
        "    sess.run(train, feed_dict=train_dict)\n",
        "    curr_error = sess.run(error, feed_dict=train_dict)\n",
        "    if i % 10 == 0:\n",
        "      accuracy = tf.equal(tf.argmax(output_placeholder, axis = 1), tf.argmax(output, axis=1))\n",
        "      accuracy_final = tf.reduce_mean(tf.cast(accuracy, tf.float32))\n",
        "\n",
        "      test_dict = {\n",
        "          input_placeholder: x_test,\n",
        "          output_placeholder: y_test\n",
        "      }\n",
        "\n",
        "      print(\"Error: {}\".format(sess.run(error, feed_dict=test_dict)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.14517712593078613\n",
            "Error: 0.10989009588956833\n",
            "Error: 0.09094343334436417\n",
            "Error: 0.0810382217168808\n",
            "Error: 0.07567958533763885\n",
            "Error: 0.07261815667152405\n",
            "Error: 0.07076913863420486\n",
            "Error: 0.06959515810012817\n",
            "Error: 0.0688168853521347\n",
            "Error: 0.06828146427869797\n",
            "Error: 0.0679011270403862\n",
            "Error: 0.06762324273586273\n",
            "Error: 0.0674150139093399\n",
            "Error: 0.06725537031888962\n",
            "Error: 0.06713033467531204\n",
            "Error: 0.06703042984008789\n",
            "Error: 0.06694908440113068\n",
            "Error: 0.06688164919614792\n",
            "Error: 0.06682475656270981\n",
            "Error: 0.06677600741386414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJg1ITZvszQK"
      },
      "source": [
        "Non-PCA + All inputs\n",
        "\n",
        "---\n",
        "\n",
        "1 hidden neuron = 0.0643\n",
        "\n",
        "**5 hidden neuron = 0.0638**\n",
        "\n",
        "10 hidden neuron = 0.0660\n",
        "\n",
        "15 hidden neuron = 0.0659\n",
        "\n",
        "20 hidden neuron = 0.0667\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcPkl7Dswl5z"
      },
      "source": [
        "\n",
        "\n",
        "> PCA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzdnZKesohvE"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yECn9PCOv3Ui"
      },
      "source": [
        "x_pca = dataset[['sex', 'Age', 'Married', 'Number_children', 'education_level', 'total_members', 'gained_asset', 'durable_asset', 'save_asset', 'living_expenses', 'other_expenses', 'incoming_salary', 'incoming_own_farm', 'incoming_business', 'incoming_no_business', 'incoming_agricultural', 'farm_expenses', 'labor_primary', 'lasting_investment', 'no_lasting_investmen']].values\n",
        "y_pca = dataset[['depressed']].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W57pve5mv-qj"
      },
      "source": [
        "scaler = StandardScaler().fit(x_pca)\n",
        "x_pca = scaler.transform(x_pca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEk5f1ccwJBM"
      },
      "source": [
        "pca = PCA(n_components=4).fit(x_pca)\n",
        "x_pca = pca.transform(x_pca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMRsxZNawBqh"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split (x_pca, y_pca, test_size = 0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt1k4hFJwOm2"
      },
      "source": [
        "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
        "y_train, y_test = y_train.astype('float32'), y_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om9tvqOBwS16"
      },
      "source": [
        "layers = {\n",
        "    'input' : 4,\n",
        "    'hidden' : 1,\n",
        "    'output' : 1\n",
        "}\n",
        "\n",
        "input_hidden = {\n",
        "    'weight': tf.Variable(tf.random_normal([layers['input'], layers['hidden']], seed=0)),\n",
        "    'bias': tf.Variable(tf.random_normal([layers['hidden']], seed=0))\n",
        "}\n",
        "\n",
        "hidden_output = {\n",
        "    'weight': tf.Variable(tf.random_normal([layers['hidden'], layers['output']], seed=0)),\n",
        "    'bias': tf.Variable(tf.random_normal([layers['output']], seed=0))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnDX12FEwWly"
      },
      "source": [
        "input_placeholder = tf.placeholder(tf.float32, [None, layers['input']])\n",
        "output_placeholder = tf.placeholder(tf.float32, [None, layers['output']])\n",
        "\n",
        "output = feed_forward(input_placeholder)\n",
        "error = tf.reduce_mean(0.5 * (output_placeholder - output) ** 2)\n",
        "\n",
        "learning_rate = 0.2\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK8XjHkKwYRn",
        "outputId": "b186fd9f-fa7d-4140-f317-129d89896232"
      },
      "source": [
        "epoch = 200\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for i in range(epoch):\n",
        "    train_dict = {\n",
        "        input_placeholder: x_train,\n",
        "        output_placeholder: y_train\n",
        "    }\n",
        "    \n",
        "    sess.run(train, feed_dict=train_dict)\n",
        "    curr_error = sess.run(error, feed_dict=train_dict)\n",
        "    if i % 10 == 0:\n",
        "      accuracy = tf.equal(tf.argmax(output_placeholder, axis = 1), tf.argmax(output, axis=1))\n",
        "      accuracy_final = tf.reduce_mean(tf.cast(accuracy, tf.float32))\n",
        "\n",
        "      test_dict = {\n",
        "          input_placeholder: x_test,\n",
        "          output_placeholder: y_test\n",
        "      }\n",
        "\n",
        "      print(\"Error: {}\".format(sess.run(error, feed_dict=test_dict)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.13025294244289398\n",
            "Error: 0.11061280220746994\n",
            "Error: 0.09583774954080582\n",
            "Error: 0.08540740609169006\n",
            "Error: 0.07846333831548691\n",
            "Error: 0.07403206825256348\n",
            "Error: 0.07126010209321976\n",
            "Error: 0.06952782720327377\n",
            "Error: 0.06843400746583939\n",
            "Error: 0.0677327811717987\n",
            "Error: 0.06727609783411026\n",
            "Error: 0.06697438657283783\n",
            "Error: 0.06677268445491791\n",
            "Error: 0.06663656234741211\n",
            "Error: 0.06654408574104309\n",
            "Error: 0.06648095697164536\n",
            "Error: 0.06643769145011902\n",
            "Error: 0.0664079412817955\n",
            "Error: 0.0663873627781868\n",
            "Error: 0.06637294590473175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4RkPa6vwopY"
      },
      "source": [
        "PCA\n",
        "\n",
        "---\n",
        "\n",
        "1 hidden neuron = 0.0652\n",
        "\n",
        "**5 hidden neuron = 0.0639**\n",
        "\n",
        "10 hidden neuron = 0.0668\n",
        "\n",
        "15 hidden neuron = 0.0658\n",
        "\n",
        "20 hidden neuron = 0.0663\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGP6KNejxQgb"
      },
      "source": [
        "Hasil paling ideal -> Non PCA + 4 Correlated Inputs dengan 5 hidden neuron\n",
        "\n",
        "Error = 0.0638\n"
      ]
    }
  ]
}